{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d59a68-c226-4e53-b4f1-2b9006a2c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "# for later versions: \n",
    "# tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# # 5. Configure a new global `tensorflow` session\n",
    "# from keras import backend as K\n",
    "# # session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# # sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "# # K.set_session(sess)\n",
    "# # for later versions:\n",
    "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# tf.compat.v1.set_random_seed(seed_value)\n",
    "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "# K.set_session(sess)\n",
    "\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "# from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fbaa94-c72f-401c-a1aa-1e1082fab0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This version does (samples, features, timestamps)\n",
    "def reshaper(data,  n_timestamps, n_features):\n",
    "    n_samples = data.shape[0]\n",
    "\n",
    "    result = np.empty((n_samples, n_features, n_timestamps))\n",
    "    for i in range(n_samples):\n",
    "        c=0\n",
    "        for j in range (n_features):\n",
    "            for k in range(n_timestamps):\n",
    "                result[i][j][k]=data[i][c]\n",
    "                c+=1\n",
    "    \n",
    "    return result\n",
    "\n",
    "# #This version does (samples, timestamps, features)\n",
    "# def reshaper(data,  n_timestamps, n_features):\n",
    "#     n_samples = data.shape[0]\n",
    "\n",
    "#     result = np.empty((n_samples, n_features, n_timestamps))\n",
    "#     for i in range(n_samples):\n",
    "#         c=0\n",
    "#         for j in range (n_features):\n",
    "#             for k in range(n_timestamps):\n",
    "#                 result[i][k][j]=data[i][c]\n",
    "#                 c+=1\n",
    "    \n",
    "#     return result\n",
    "\n",
    "def differentiate_column(column):\n",
    "    return column.diff().fillna(0)  # Using .diff() for differencing and filling NaNs with 0\n",
    "\n",
    "def supervisedReframer(df, steps_back=1, steps_forward=1):\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['Date'] = pd.to_datetime(df['Date'], origin='1899-12-30', unit='D')\n",
    "\n",
    "    # for col in df.columns:\n",
    "    #     if col != \"Date\":\n",
    "    #         df[col] =  differentiate_column(df[col])\n",
    "\n",
    "    shifted_cols = {}\n",
    "    for col in df.columns:\n",
    "        if col != \"Date\":\n",
    "            for shift in range(steps_back, -1, -1):\n",
    "                if shift != 0:\n",
    "                    new_col_name = f\"{col} (t-{shift})\"\n",
    "                else:\n",
    "                    new_col_name = f\"{col}\"\n",
    "                shifted_cols[new_col_name] = df[col].shift(+shift).copy()\n",
    "\n",
    "    \n",
    "    target_col = {}\n",
    "    for steps in range(1, steps_forward+1):\n",
    "        new_col_name = f\"Target (t+{steps})\"\n",
    "        target_col[new_col_name] = df['Adj Close'].shift(-steps).copy()\n",
    "\n",
    "    # Concatenate shifted columns\n",
    "    shifted_df = pd.DataFrame(shifted_cols)\n",
    "    new_df = pd.concat([new_df, shifted_df], axis=1)\n",
    "\n",
    "    # Concatenate target column\n",
    "    target_df = pd.DataFrame(target_col)\n",
    "    new_df = pd.concat([new_df, target_df], axis=1)\n",
    "    \n",
    "    new_df.dropna(inplace=True)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def TrainValTestSplit(dataframe, backwards_steps=1,forward_steps=1, n_features=1):\n",
    "    forward_steps+=1\n",
    "    df=dataframe.copy()\n",
    "    df['Year'] = df['Date'].dt.year.copy()\n",
    "\n",
    "    # Determine the years for training, validation, and testing\n",
    "    training_years = df['Year'].unique()[:-2]  # All years except the last two\n",
    "    validation_year = df['Year'].unique()[-2]  # Second to last year\n",
    "    testing_year = df['Year'].unique()[-1]  # Last year\n",
    "\n",
    "    # Select columns for X and y\n",
    "    X_columns = df.columns[1:-forward_steps]\n",
    "    y_columns = df.columns[-forward_steps:-1]\n",
    "    \n",
    "    # Filter the data based on the years\n",
    "    X_train = df[df['Year'].isin(training_years)][X_columns].values\n",
    "    y_train = df[df['Year'].isin(training_years)][y_columns].values\n",
    "    \n",
    "    X_val = df[df['Year'] == validation_year][X_columns].values\n",
    "    y_val = df[df['Year'] == validation_year][y_columns].values\n",
    "    \n",
    "    X_test = df[df['Year'] == testing_year][X_columns].values\n",
    "    y_test = df[df['Year'] == testing_year][y_columns].values\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.fit_transform(X_val)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    \n",
    "    y_train = scaler.fit_transform(y_train)\n",
    "    y_val = scaler.fit_transform(y_val)\n",
    "    y_test = scaler.fit_transform(y_test)\n",
    "\n",
    "    X_train = reshaper(X_train, backwards_steps+1, n_features)\n",
    "    X_val = reshaper(X_val, backwards_steps+1, n_features)\n",
    "    X_test = reshaper(X_test, backwards_steps+1, n_features)\n",
    "\n",
    "    # (Samples, timestamps, features version)!!!!\n",
    "    # y_train = y_train.reshape((y_train.shape[0], forward_steps-1, 1))\n",
    "    # y_val = y_val.reshape((y_val.shape[0], forward_steps-1, 1))\n",
    "    # y_test = y_test.reshape((y_test.shape[0], forward_steps-1, 1))\n",
    "\n",
    "    # (Samples, features, timestamps) version!\n",
    "    y_train = y_train.reshape((y_train.shape[0], 1, forward_steps-1))\n",
    "    y_val = y_val.reshape((y_val.shape[0], 1, forward_steps-1))\n",
    "    y_test = y_test.reshape((y_test.shape[0], 1, forward_steps-1))\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c2304-b4ce-4810-96bd-37724b73fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_back = 90 # Ako je 0, to znaci da koristis danas da predvidis sutra\n",
    "n_steps_forward = 30 #Ako je 0, jbg ne predvidjas ista\n",
    "\n",
    "# load dataset\n",
    "dataset = read_csv('CSV Files with Calculated Indicators/NYSE.csv', low_memory=False, header=0, index_col=None)\n",
    "\n",
    "df = dataset\n",
    "\n",
    "# df = pd.DataFrame({\n",
    "#     'Date': dataset['Date'], \n",
    "#     'Adj Close': dataset['Adj Close']})\n",
    "\n",
    "n_features = df.shape[1]-1\n",
    "\n",
    "moved_df = supervisedReframer(df, n_steps_back, n_steps_forward).copy()\n",
    "\n",
    "X_train,y_train,X_val,y_val,X_test,y_test = TrainValTestSplit(moved_df,n_steps_back,n_steps_forward,n_features)\n",
    "\n",
    "memory_usage = moved_df.memory_usage(deep=True).sum() / (1024 * 1024)  # Convert bytes to megabytes\n",
    "print(\"Memory usage of DataFrame: {:.2f} MB\".format(memory_usage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba2b802-f13c-4a30-8d04-48e06f284a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the model\n",
    "inputs = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "x = keras.layers.LSTM(50, return_sequences=True)(inputs)\n",
    "x = keras.layers.LSTM(25, return_sequences=True)(x)\n",
    "x = keras.layers.LSTM(10)(x)\n",
    "outputs = keras.layers.Dense(n_steps_forward, activation='linear')(x)\n",
    "\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=0.1)\n",
    "# model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss=\"mse\")\n",
    "model.summary()\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=5,           # Number of epochs to wait before stopping\n",
    "    restore_best_weights=True  # Restore weights to the best observed during training\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs = 2,\n",
    "    batch_size = 48,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1,\n",
    "    shuffle=False\n",
    "    # callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "y_test_reshaped = y_test.reshape((y_test.shape[0], y_test.shape[2]))\n",
    "\n",
    "# estimate the R2 on the test set\n",
    "print(\"LSTM coefficient of determination of the prediction: \", r2_score(y_test_reshaped, model.predict(X_test)))\n",
    "\n",
    "X_test_skimmed = X_test[::n_steps_forward]\n",
    "y_test_skimmed = y_test_reshaped[::n_steps_forward]\n",
    "\n",
    "predictions = model.predict(X_test_skimmed)\n",
    "\n",
    "y_test_skimmed = y_test_skimmed.flatten()\n",
    "\n",
    "predictions = predictions.ravel()\n",
    "\n",
    "graph_df = pd.DataFrame({\n",
    "    'True': y_test_skimmed, \n",
    "    'Predictions': predictions})\n",
    "\n",
    "last_n_dates = df['Date'].tail(len(graph_df)).tolist()\n",
    "graph_df['Date'] = last_n_dates\n",
    "\n",
    "graph_df['Date'] = pd.to_datetime(graph_df['Date'], origin='1899-12-30', unit='D')\n",
    "\n",
    "graph_df['Predictions'] = graph_df['Predictions'].shift(-1)\n",
    "\n",
    "#Plotting\n",
    "x_min = graph_df['Date'].iloc[0]  # Replace with your desired minimum x-axis value\n",
    "x_max = graph_df['Date'].iloc[-1]  # Replace with your desired maximum x-axis value\n",
    "y_min = min(graph_df['True'].min(), graph_df['Predictions'].min())  # Replace with your desired minimum y-axis value\n",
    "y_max = max(graph_df['True'].max(), graph_df['Predictions'].max())  # Replace with your desired maximum y-axis value\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Replace 'Date', 'Close', and 'Predicted' with your actual column names\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(graph_df['Date'], graph_df['True'], label='Close', linewidth=1)\n",
    "plt.plot(graph_df['Date'], graph_df['Predictions'], label='Predictions', linestyle='dashed', color='red', linewidth=1)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Adj Close vs. Predicted Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "\n",
    "# Set x-axis and y-axis value ranges\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "\n",
    "plt.grid(False)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6956cf5-d352-41eb-b56a-902d254bc998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store the history\n",
    "combined_history = {}\n",
    "\n",
    "# Check if there is existing history\n",
    "if 'history' in locals():\n",
    "    # If history exists, add it to the combined history\n",
    "    for key in history.history.keys():\n",
    "        combined_history[key] = history.history[key]\n",
    "\n",
    "# Train the model again, assuming `model` is already defined\n",
    "new_history = model.fit(\n",
    "    X_train, y_train,  # Use your new training data\n",
    "    epochs=1,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),  # Use your new validation data\n",
    "    verbose=1,\n",
    "    shuffle=False\n",
    "    # callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Update the combined history with the new history\n",
    "for key in new_history.history.keys():\n",
    "    if key in combined_history:\n",
    "        combined_history[key].extend(new_history.history[key])\n",
    "    else:\n",
    "        combined_history[key] = new_history.history[key]\n",
    "\n",
    "# estimate the R2 on the test set\n",
    "print(\"LSTM coefficient of determination of the prediction: \", r2_score(y_test_reshaped, model.predict(X_test)))\n",
    "\n",
    "# fit model\n",
    "plt.plot(combined_history['loss'], label='train')\n",
    "plt.plot(combined_history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "X_test_skimmed = X_test[::n_steps_forward]\n",
    "y_test_skimmed = y_test_reshaped[::n_steps_forward]\n",
    "\n",
    "predictions = model.predict(X_test_skimmed)\n",
    "\n",
    "y_test_skimmed = y_test_skimmed.flatten()\n",
    "\n",
    "predictions = predictions.ravel()\n",
    "\n",
    "graph_df = pd.DataFrame({\n",
    "    'True': y_test_skimmed, \n",
    "    'Predictions': predictions})\n",
    "\n",
    "last_n_dates = df['Date'].tail(len(graph_df)).tolist()\n",
    "graph_df['Date'] = last_n_dates\n",
    "\n",
    "graph_df['Date'] = pd.to_datetime(graph_df['Date'], origin='1899-12-30', unit='D')\n",
    "\n",
    "graph_df['Predictions'] = graph_df['Predictions'].shift(-1)\n",
    "\n",
    "#Plotting\n",
    "x_min = graph_df['Date'].iloc[0]  # Replace with your desired minimum x-axis value\n",
    "x_max = graph_df['Date'].iloc[-1]  # Replace with your desired maximum x-axis value\n",
    "y_min = min(graph_df['True'].min(), graph_df['Predictions'].min())  # Replace with your desired minimum y-axis value\n",
    "y_max = max(graph_df['True'].max(), graph_df['Predictions'].max())  # Replace with your desired maximum y-axis value\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Replace 'Date', 'Close', and 'Predicted' with your actual column names\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(graph_df['Date'], graph_df['True'], label='Close', linewidth=1)\n",
    "plt.plot(graph_df['Date'], graph_df['Predictions'], label='Predictions', linestyle='dashed', color='red', linewidth=1)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Adj Close vs. Predicted Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "\n",
    "# Set x-axis and y-axis value ranges\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "\n",
    "plt.grid(False)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
