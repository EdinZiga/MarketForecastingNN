{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5cf6d01-9a79-4d88-be64-51cd83765d84",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'datetime' from 'pandas' (C:\\Users\\Edin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_csv\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'datetime' from 'pandas' (C:\\Users\\Edin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b0db3d-e83e-4333-a7e5-2b896e74be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date-time parsing function for loading the dataset\n",
    "def parser(x):\n",
    "\treturn datetime.strptime('190'+x, '%Y-%m')\n",
    "\n",
    "# convert time series into supervised learning problem\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# transform series into train and test sets for supervised learning\n",
    "def prepare_data(series, n_test, n_lag, n_seq):\n",
    "\t# extract raw values\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff_series = difference(raw_values, 1)\n",
    "\tdiff_values = diff_series.values\n",
    "\tdiff_values = diff_values.reshape(len(diff_values), 1)\n",
    "\t# rescale values to -1, 1\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaled_values = scaler.fit_transform(diff_values)\n",
    "\tscaled_values = scaled_values.reshape(len(scaled_values), 1)\n",
    "\t# transform into supervised learning problem X, y\n",
    "\tsupervised = series_to_supervised(scaled_values, n_lag, n_seq)\n",
    "\tsupervised_values = supervised.values\n",
    "\t# split into train and test sets\n",
    "\ttrain, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n",
    "\treturn scaler, train, test\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, n_lag, n_seq, n_batch, nb_epoch, n_neurons):\n",
    "\t# reshape training into [samples, timesteps, features]\n",
    "\tX, y = train[:, 0:n_lag], train[:, n_lag:]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\t# design network\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(y.shape[1]))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\t# fit network\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=n_batch, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\treturn model\n",
    "\n",
    "# make one forecast with an LSTM,\n",
    "def forecast_lstm(model, X, n_batch):\n",
    "\t# reshape input pattern to [samples, timesteps, features]\n",
    "\tX = X.reshape(1, 1, len(X))\n",
    "\t# make forecast\n",
    "\tforecast = model.predict(X, batch_size=n_batch)\n",
    "\t# convert to array\n",
    "\treturn [x for x in forecast[0, :]]\n",
    "\n",
    "# evaluate the persistence model\n",
    "def make_forecasts(model, n_batch, train, test, n_lag, n_seq):\n",
    "\tforecasts = list()\n",
    "\tfor i in range(len(test)):\n",
    "\t\tX, y = test[i, 0:n_lag], test[i, n_lag:]\n",
    "\t\t# make forecast\n",
    "\t\tforecast = forecast_lstm(model, X, n_batch)\n",
    "\t\t# store the forecast\n",
    "\t\tforecasts.append(forecast)\n",
    "\treturn forecasts\n",
    "\n",
    "# invert differenced forecast\n",
    "def inverse_difference(last_ob, forecast):\n",
    "\t# invert first forecast\n",
    "\tinverted = list()\n",
    "\tinverted.append(forecast[0] + last_ob)\n",
    "\t# propagate difference forecast using inverted first value\n",
    "\tfor i in range(1, len(forecast)):\n",
    "\t\tinverted.append(forecast[i] + inverted[i-1])\n",
    "\treturn inverted\n",
    "\n",
    "# inverse data transform on forecasts\n",
    "def inverse_transform(series, forecasts, scaler, n_test):\n",
    "\tinverted = list()\n",
    "\tfor i in range(len(forecasts)):\n",
    "\t\t# create array from forecast\n",
    "\t\tforecast = array(forecasts[i])\n",
    "\t\tforecast = forecast.reshape(1, len(forecast))\n",
    "\t\t# invert scaling\n",
    "\t\tinv_scale = scaler.inverse_transform(forecast)\n",
    "\t\tinv_scale = inv_scale[0, :]\n",
    "\t\t# invert differencing\n",
    "\t\tindex = len(series) - n_test + i - 1\n",
    "\t\tlast_ob = series.values[index]\n",
    "\t\tinv_diff = inverse_difference(last_ob, inv_scale)\n",
    "\t\t# store\n",
    "\t\tinverted.append(inv_diff)\n",
    "\treturn inverted\n",
    "\n",
    "# evaluate the RMSE for each forecast time step\n",
    "def evaluate_forecasts(test, forecasts, n_lag, n_seq):\n",
    "\tfor i in range(n_seq):\n",
    "\t\tactual = [row[i] for row in test]\n",
    "\t\tpredicted = [forecast[i] for forecast in forecasts]\n",
    "\t\trmse = sqrt(mean_squared_error(actual, predicted))\n",
    "\t\tprint('t+%d RMSE: %f' % ((i+1), rmse))\n",
    "\n",
    "# plot the forecasts in the context of the original dataset\n",
    "def plot_forecasts(series, forecasts, n_test):\n",
    "\t# plot the entire dataset in blue\n",
    "\tpyplot.plot(series.values)\n",
    "\t# plot the forecasts in red\n",
    "\tfor i in range(len(forecasts)):\n",
    "\t\toff_s = len(series) - n_test + i - 1\n",
    "\t\toff_e = off_s + len(forecasts[i]) + 1\n",
    "\t\txaxis = [x for x in range(off_s, off_e)]\n",
    "\t\tyaxis = [series.values[off_s]] + forecasts[i]\n",
    "\t\tpyplot.plot(xaxis, yaxis, color='red')\n",
    "\t# show the plot\n",
    "\tpyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ee1dda-2ae3-450e-bdab-53f6df841bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edin\\AppData\\Local\\Temp\\ipykernel_10620\\326008905.py:2: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  series = read_csv('shampoo.csv', header=0, parse_dates=[0], index_col=0, date_parser=parser)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:1190\u001b[0m, in \u001b[0;36m_make_date_converter.<locals>.converter\u001b[1;34m(col, *date_cols)\u001b[0m\n\u001b[0;32m   1184\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[0;32m   1185\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*parsing datetimes with mixed time zones \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill raise an error\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1188\u001b[0m     category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m   1189\u001b[0m )\n\u001b[1;32m-> 1190\u001b[0m pre_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mdate_parser\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munpack_if_single_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdate_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m, in \u001b[0;36mparser\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparser\u001b[39m(x):\n\u001b[1;32m----> 3\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdatetime\u001b[49m\u001b[38;5;241m.\u001b[39mstrptime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m190\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# load dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshampoo.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# configure\u001b[39;00m\n\u001b[0;32m      4\u001b[0m n_lag \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:333\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    330\u001b[0m     data \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, (i, v) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(names, data_tups)}\n\u001b[0;32m    332\u001b[0m     names, date_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_date_conversions(names, data)\n\u001b[1;32m--> 333\u001b[0m     index, column_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malldata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index, column_names, date_data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:372\u001b[0m, in \u001b[0;36mParserBase._make_index\u001b[1;34m(self, data, alldata, columns, indexnamerow)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_complex_date_col:\n\u001b[0;32m    371\u001b[0m     simple_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_simple_index(alldata, columns)\n\u001b[1;32m--> 372\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agg_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimple_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_complex_date_col:\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_processed:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:469\u001b[0m, in \u001b[0;36mParserBase._agg_index\u001b[1;34m(self, index, try_parse_dates)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, arr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(index):\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m try_parse_dates \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_parse_dates(i):\n\u001b[1;32m--> 469\u001b[0m         arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_date_conv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m            \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mna_filter:\n\u001b[0;32m    475\u001b[0m         col_na_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mna_values\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:1213\u001b[0m, in \u001b[0;36m_make_date_converter.<locals>.converter\u001b[1;34m(col, *date_cols)\u001b[0m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m   1207\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[0;32m   1208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*parsing datetimes with mixed time zones \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill raise an error\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1211\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m   1212\u001b[0m     )\n\u001b[1;32m-> 1213\u001b[0m     pre_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mparsing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_parse_dates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparsing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat_date_cols\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_cols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1217\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tools\u001b[38;5;241m.\u001b[39mto_datetime(pre_parsed)\n",
      "File \u001b[1;32mparsing.pyx:799\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.try_parse_dates\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m, in \u001b[0;36mparser\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparser\u001b[39m(x):\n\u001b[1;32m----> 3\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdatetime\u001b[49m\u001b[38;5;241m.\u001b[39mstrptime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m190\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "series = read_csv('shampoo.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "# configure\n",
    "n_lag = 1\n",
    "n_seq = 3\n",
    "n_test = 10\n",
    "n_epochs = 1500\n",
    "n_batch = 1\n",
    "n_neurons = 1\n",
    "# prepare data\n",
    "scaler, train, test = prepare_data(series, n_test, n_lag, n_seq)\n",
    "# fit model\n",
    "model = fit_lstm(train, n_lag, n_seq, n_batch, n_epochs, n_neurons)\n",
    "# make forecasts\n",
    "forecasts = make_forecasts(model, n_batch, train, test, n_lag, n_seq)\n",
    "# inverse transform forecasts and test\n",
    "forecasts = inverse_transform(series, forecasts, scaler, n_test+2)\n",
    "actual = [row[n_lag:] for row in test]\n",
    "actual = inverse_transform(series, actual, scaler, n_test+2)\n",
    "# evaluate forecasts\n",
    "evaluate_forecasts(actual, forecasts, n_lag, n_seq)\n",
    "# plot forecasts\n",
    "plot_forecasts(series, forecasts, n_test+2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
